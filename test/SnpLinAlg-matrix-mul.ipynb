{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling SnpArrays [4e780e97-f5bf-4111-9dc4-b70aaf691b06]\n",
      "└ @ Base loading.jl:1317\n",
      "WARNING: could not import DataFrames.DataFrame! into SnpArrays\n",
      "┌ Info: Precompiling MendelIHT [921c7187-1484-5754-b919-5d3ed9ac03c4]\n",
      "└ @ Base loading.jl:1317\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness: No center/scale/impute\n",
    "We want to do $C = AB$ where\n",
    "+ $C = m \\times n$\n",
    "+ $A = m \\times n$\n",
    "+ $B = n \\times p$\n",
    "+ SnpArray model = Additive, dominant, recessive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all(C .≈ Ctrue) = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ADDITIVE_MODEL\n",
    "center = false\n",
    "scale = false\n",
    "impute = false\n",
    "m = 4097\n",
    "n = 1025\n",
    "p = 1025\n",
    "x = simulate_random_snparray(undef, m, n)\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=model, impute=impute, center=center, scale=scale)\n",
    "B = ones(n, p)\n",
    "C = zeros(m, p)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "\n",
    "Ctrue = convert(Matrix{Float64}, x, impute=impute, model=model, center=center, scale=scale) * B\n",
    "@show all(C .≈ Ctrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness: center/scale/impute\n",
    "\n",
    "If we want to center/scale the SnpArray, we have\n",
    "$$\n",
    "C_{ij} = \\sum_{k} \\left(\\frac{A_{ik} - \\mu_k}{\\sigma_k^2}\\right)B_{kj} = \\sum_{k} \\frac{A_{ik}B_{kj} - \\mu_kB_{kj}}{\\sigma_k^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all(C .≈ Ctrue) = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ADDITIVE_MODEL\n",
    "center = true\n",
    "scale = true\n",
    "impute = true\n",
    "m = 4097\n",
    "n = 1025\n",
    "p = 1025\n",
    "x = simulate_random_snparray(undef, m, n)\n",
    "if impute\n",
    "    for j in 1:n, i in 1:m\n",
    "        rand() < 0.01 && (x[i, j] = 0x01) # create ~1% missings\n",
    "    end\n",
    "end\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=model, impute=impute, center=center, scale=scale)\n",
    "B = ones(n, p)\n",
    "C = zeros(m, p)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "\n",
    "Ctrue = convert(Matrix{Float64}, x, impute=impute, model=model, center=center, scale=scale) * B\n",
    "@show all(C .≈ Ctrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed: SnpLinAlg-(matrix) vs multiple SnpLinAlg-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adhoc_mul! (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C = AB by multiple C[:, i] = AB[:, i]\n",
    "function adhoc_mul!(\n",
    "    out::AbstractMatrix, \n",
    "    st::AbstractSnpLinAlg,\n",
    "    v::AbstractMatrix)\n",
    "    for i in 1:size(v, 2)\n",
    "        outi = @view(out[:, i])\n",
    "        vi = @view(v[:, i])\n",
    "        SnpArrays.mul!(outi, st, vi)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5092   # number of samples\n",
    "p = 10000  # number of SNPs\n",
    "r = 2      # number of traits\n",
    "x = simulate_random_snparray(undef, n, p)\n",
    "\n",
    "# test correctness\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=true, center=true, scale=true)\n",
    "B = ones(p, r)\n",
    "C = zeros(n, r)\n",
    "Ctest = zeros(n, r)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "adhoc_mul!(Ctest, A, B)\n",
    "all(Ctest .≈ C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     33.984 ms (0.00% GC)\n",
       "  median time:      35.574 ms (0.00% GC)\n",
       "  mean time:        35.681 ms (0.00% GC)\n",
       "  maximum time:     48.416 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          141\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearAlgebra.mul!($C, $A, $B) # SnpLinAlg-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     33.801 ms (0.00% GC)\n",
       "  median time:      35.612 ms (0.00% GC)\n",
       "  mean time:        44.915 ms (0.00% GC)\n",
       "  maximum time:     97.297 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          112\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark adhoc_mul!($Ctest, $A, $B) # multiple SnpLinAlg-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     17.488 ms (0.00% GC)\n",
       "  median time:      18.473 ms (0.00% GC)\n",
       "  mean time:        19.304 ms (0.00% GC)\n",
       "  maximum time:     23.870 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          259\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Afloat = convert(Matrix{Float64}, A)\n",
    "BLAS.set_num_threads(8)\n",
    "@benchmark LinearAlgebra.mul!($C, $Afloat, $B) # BLAS with 8 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     49.005 ms (0.00% GC)\n",
       "  median time:      50.821 ms (0.00% GC)\n",
       "  mean time:        51.015 ms (0.00% GC)\n",
       "  maximum time:     57.021 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          98\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.set_num_threads(1)\n",
    "@benchmark LinearAlgebra.mul!($C, $Afloat, $B) # BLAS with 1 threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 5092\n",
    "p = 10000\n",
    "r = 5\n",
    "x = simulate_random_snparray(undef, n, p)\n",
    "\n",
    "# test correctness\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=true, center=true, scale=true)\n",
    "B = ones(p, r)\n",
    "C = zeros(n, r)\n",
    "Ctest = zeros(n, r)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "adhoc_mul!(Ctest, A, B)\n",
    "all(Ctest .≈ C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     52.632 ms (0.00% GC)\n",
       "  median time:      56.090 ms (0.00% GC)\n",
       "  mean time:        62.038 ms (0.00% GC)\n",
       "  maximum time:     134.616 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          81\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearAlgebra.mul!($C, $A, $B) # SnpLinAlg-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  480 bytes\n",
       "  allocs estimate:  5\n",
       "  --------------\n",
       "  minimum time:     88.873 ms (0.00% GC)\n",
       "  median time:      92.703 ms (0.00% GC)\n",
       "  mean time:        98.438 ms (0.00% GC)\n",
       "  maximum time:     224.836 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          51\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark adhoc_mul!($Ctest, $A, $B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     18.761 ms (0.00% GC)\n",
       "  median time:      20.697 ms (0.00% GC)\n",
       "  mean time:        21.208 ms (0.00% GC)\n",
       "  maximum time:     27.362 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          236\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Afloat = convert(Matrix{Float64}, A)\n",
    "BLAS.set_num_threads(8)\n",
    "@benchmark LinearAlgebra.mul!($C, $Afloat, $B) # BLAS with 8 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     56.292 ms (0.00% GC)\n",
       "  median time:      59.270 ms (0.00% GC)\n",
       "  mean time:        59.264 ms (0.00% GC)\n",
       "  maximum time:     66.171 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          85\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.set_num_threads(1)\n",
    "@benchmark LinearAlgebra.mul!($C, $Afloat, $B) # BLAS with 1 threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gesp vs @view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5092\n",
    "p = 1000\n",
    "q = 1000\n",
    "x = simulate_random_snparray(undef, n, p)\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "B = ones(p, q)\n",
    "C = zeros(n, q);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     1.104 s (0.00% GC)\n",
       "  median time:      1.113 s (0.00% GC)\n",
       "  mean time:        1.113 s (0.00% GC)\n",
       "  maximum time:     1.118 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearAlgebra.mul!($C, $A, $B) # gesp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     1.112 s (0.00% GC)\n",
       "  median time:      1.120 s (0.00% GC)\n",
       "  mean time:        1.120 s (0.00% GC)\n",
       "  maximum time:     1.126 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearAlgebra.mul!($C, $A, $B) # @view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Ax$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 1023, Miter = 0, Mrem = 253, rows_filled = 4093 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT\n",
    "using Test\n",
    "\n",
    "# any n between 4097 and 4099 doesn't work!\n",
    "n = 4093\n",
    "p = 10000\n",
    "x = simulate_random_snparray(undef, n, p, min_ma=0)\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "b = ones(p)\n",
    "c = A * b\n",
    "ctrue = convert(Matrix{Float64}, A) * b\n",
    "@test all(c .≈ ctrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $A^tx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT\n",
    "using Test\n",
    "\n",
    "# any n between 8193 and 8195 doesn't work!\n",
    "n = 8193\n",
    "p = 1000\n",
    "x = simulate_random_snparray(undef, n, p, min_ma=0)\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "b = ones(n)\n",
    "c = A' * b\n",
    "ctrue = convert(Matrix{Float64}, A)' * b\n",
    "@test all(c .≈ ctrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## $Ax$ with mean impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT\n",
    "using Test\n",
    "\n",
    "n = 4097\n",
    "p = 10000\n",
    "x = simulate_random_snparray(undef, n, p, min_ma=0) # no missing data\n",
    "x[1, 1025] = 0x01 # missing\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=true, center=false, scale=false)\n",
    "Atrue = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, impute=true, center=false, scale=false)\n",
    "b = ones(p)\n",
    "c = A * b\n",
    "ctrue = Atrue * b\n",
    "@test all(c .≈ ctrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vashr error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_gemm_manual_unroll (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using Test\n",
    "\n",
    "expr = :((Aij == 3) * V[j, c])\n",
    "\n",
    "function my_gemm(out, s::Matrix{UInt8}, V)\n",
    "    fill!(out, 0)\n",
    "    Vcols = size(V, 2)\n",
    "    srows = size(s, 1)\n",
    "    scols = size(s, 2)\n",
    "    for c in 1:Vcols\n",
    "        for j in 1:scols\n",
    "            for i in 1:srows\n",
    "                ip3 = i + 3\n",
    "                Aij = (s[ip3 >> 2, j] >> ((ip3 & 0x03) << 1)) & 0x03\n",
    "                out[i, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function my_gemm_avx(out, s::Matrix{UInt8}, V)\n",
    "    fill!(out, 0)\n",
    "    Vcols = size(V, 2)\n",
    "    srows = size(s, 1)\n",
    "    scols = size(s, 2)\n",
    "    @avx for c in 1:Vcols\n",
    "        for j in 1:scols\n",
    "            for i in 1:srows\n",
    "                ip3 = i + 3\n",
    "                Aij = (s[ip3 >> 2, j] >> ((ip3 & 0x03) << 1)) & 0x03\n",
    "                out[i, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function my_gemm_unroll(out, s::Matrix{UInt8}, V)\n",
    "    fill!(out, 0)\n",
    "    Vcols = size(V, 2)\n",
    "    srows = size(s, 1)\n",
    "    scols = size(s, 2)\n",
    "    k = srows >> 2\n",
    "    rem = srows & 3\n",
    "    @avx for c in 1:Vcols\n",
    "        for j in 1:scols\n",
    "            for l in 1:k\n",
    "                block = s[l, j]\n",
    "                for p in 1:4\n",
    "                    Aij = (block >> (2 * (p - 1))) & 3\n",
    "                    out[4*(l - 1) + p, c] += $expr\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    # TODO handle rem\n",
    "end\n",
    "\n",
    "function my_gemm_manual_unroll(out, s::Matrix{UInt8}, V)\n",
    "    fill!(out, 0)\n",
    "    Vcols = size(V, 2)\n",
    "    srows = size(s, 1)\n",
    "    scols = size(s, 2)\n",
    "    k = srows >> 2\n",
    "    rem = srows & 3\n",
    "    @avx for c in 1:Vcols\n",
    "        for j in 1:scols\n",
    "            for l in 1:k\n",
    "                block = s[l, j]\n",
    "                # unrolled loop\n",
    "                p = 1\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 2\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 3\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 4\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    # TODO handle rem\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_true = zeros(100, 10)\n",
    "out_test1 = zeros(100, 10)\n",
    "out_test2 = zeros(100, 10)\n",
    "out_test3 = zeros(100, 10)\n",
    "s = rand(UInt8, 25, 100)\n",
    "V = rand(100, 10)\n",
    "\n",
    "my_gemm(out_true, s, V)\n",
    "my_gemm_avx(out_test1, s, V)\n",
    "@test all(out_true .≈ out_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[21]:3\u001b[22m\n",
      "  Expression: all(out_true .≈ out_test2)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mThere was an error during testing\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mThere was an error during testing\u001b[39m",
      "",
      "Stacktrace:",
      " [1] record(ts::Test.FallbackTestSet, t::Union{Test.Error, Test.Fail})",
      "   @ Test /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:772",
      " [2] do_test(result::Test.ExecutionResult, orig_expr::Any)",
      "   @ Test /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:555",
      " [3] top-level scope",
      "   @ In[21]:3",
      " [4] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "my_gemm_manual_unroll(out_test2, s, V)\n",
    "@test all(out_true .≈ out_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching vashr(::VectorizationBase.VecUnroll{1, 4, UInt8, VectorizationBase.Vec{4, UInt8}}, ::VectorizationBase.Vec{4, UInt8})\n\u001b[0mClosest candidates are:\n\u001b[0m  vashr(::Any, \u001b[91m::Static.StaticInt{M}\u001b[39m) where M at /Users/biona001/.julia/packages/VectorizationBase/ax8db/src/static.jl:43\n\u001b[0m  vashr(\u001b[91m::Static.StaticInt{M}\u001b[39m, ::Any) where M at /Users/biona001/.julia/packages/VectorizationBase/ax8db/src/static.jl:42\n\u001b[0m  vashr(\u001b[91m::VectorizationBase.MM{W, X, T1}\u001b[39m, ::VectorizationBase.AbstractSIMDVector{W, T2}) where {W, X, T1<:Union{Int16, Int32, Int64, Int8}, T2<:Union{UInt16, UInt32, UInt64, UInt8}} at /Users/biona001/.julia/packages/VectorizationBase/ax8db/src/ranges.jl:207\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching vashr(::VectorizationBase.VecUnroll{1, 4, UInt8, VectorizationBase.Vec{4, UInt8}}, ::VectorizationBase.Vec{4, UInt8})\n\u001b[0mClosest candidates are:\n\u001b[0m  vashr(::Any, \u001b[91m::Static.StaticInt{M}\u001b[39m) where M at /Users/biona001/.julia/packages/VectorizationBase/ax8db/src/static.jl:43\n\u001b[0m  vashr(\u001b[91m::Static.StaticInt{M}\u001b[39m, ::Any) where M at /Users/biona001/.julia/packages/VectorizationBase/ax8db/src/static.jl:42\n\u001b[0m  vashr(\u001b[91m::VectorizationBase.MM{W, X, T1}\u001b[39m, ::VectorizationBase.AbstractSIMDVector{W, T2}) where {W, X, T1<:Union{Int16, Int32, Int64, Int8}, T2<:Union{UInt16, UInt32, UInt64, UInt8}} at /Users/biona001/.julia/packages/VectorizationBase/ax8db/src/ranges.jl:207\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] >>",
      "   @ ~/.julia/packages/VectorizationBase/ax8db/src/base_defs.jl:176 [inlined]",
      " [2] macro expansion",
      "   @ ~/.julia/packages/LoopVectorization/OVqp6/src/reconstruct_loopset.jl:706 [inlined]",
      " [3] _turbo_!(::Val{(false, 0, 0, false, 4, 32, 15, 64, 32768, 262144, 16777216, 0x0000000000000001)}, ::Val{(:LoopVectorization, :getindex, LoopVectorization.OperationStruct(0x00000000000000000000000000000032, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, LoopVectorization.memload, 0x01, 0x01), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, LoopVectorization.constant, 0x00, 0x02), :p, :p, LoopVectorization.OperationStruct(0x00000000000000000000000000000004, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, LoopVectorization.loopvalue, 0x00, 0x03), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, LoopVectorization.constant, 0x00, 0x04), :LoopVectorization, :sub_fast, LoopVectorization.OperationStruct(0x00000000000000000000000000000004, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000304, LoopVectorization.compute, 0x00, 0x05), :LoopVectorization, :mul_fast, LoopVectorization.OperationStruct(0x00000000000000000000000000000004, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000205, LoopVectorization.compute, 0x00, 0x06), :LoopVectorization, :>>, LoopVectorization.OperationStruct(0x00000000000000000000000000000324, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000106, LoopVectorization.compute, 0x00, 0x07), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, LoopVectorization.constant, 0x00, 0x08), :LoopVectorization, :&, LoopVectorization.OperationStruct(0x00000000000000000000000000000324, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000708, LoopVectorization.compute, 0x00, 0x09), :l, :l, LoopVectorization.OperationStruct(0x00000000000000000000000000000003, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, LoopVectorization.loopvalue, 0x00, 0x0a), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, LoopVectorization.constant, 0x00, 0x0b), :LoopVectorization, :muladd, LoopVectorization.OperationStruct(0x00000000000000000000000000000034, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x000000000000000000000000000b0a03, LoopVectorization.compute, 0x00, 0x0c), :LoopVectorization, :>=, LoopVectorization.OperationStruct(0x00000000000000000000000000000324, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000902, LoopVectorization.compute, 0x00, 0x0d), :LoopVectorization, :(==), LoopVectorization.OperationStruct(0x00000000000000000000000000000324, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000908, LoopVectorization.compute, 0x00, 0x0e), :LoopVectorization, :add_fast, LoopVectorization.OperationStruct(0x00000000000000000000000000000324, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000d0e, LoopVectorization.compute, 0x00, 0x0f), :LoopVectorization, :getindex, LoopVectorization.OperationStruct(0x00000000000000000000000000000021, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, LoopVectorization.memload, 0x02, 0x10), :LoopVectorization, :getindex, LoopVectorization.OperationStruct(0x00000000000000000000000000000341, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x0000000000000000000000000000000c, LoopVectorization.memload, 0x03, 0x11), :numericconstant, Symbol(\"###reduction##zero###27###\"), LoopVectorization.OperationStruct(0x00000000000000000000000000000341, 0x00000000000000000000000000000000, 0x00000000000000000000000000000002, 0x00000000000000000000000000000000, LoopVectorization.constant, 0x00, 0x12), :LoopVectorization, :vfmadd_fast, LoopVectorization.OperationStruct(0x00000000000000000000000000003241, 0x00000000000000000000000000000002, 0x00000000000000000000000000000000, 0x000000000000000000000000000f1012, LoopVectorization.compute, 0x00, 0x12), :LoopVectorization, :reduced_add, LoopVectorization.OperationStruct(0x00000000000000000000000000000341, 0x00000000000000000000000000000002, 0x00000000000000000000000000000000, 0x00000000000000000000000000001311, LoopVectorization.compute, 0x00, 0x11), :LoopVectorization, :setindex!, LoopVectorization.OperationStruct(0x00000000000000000000000000000341, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x0000000000000000000000000000140c, LoopVectorization.memstore, 0x03, 0x13))}, ::Val{(LoopVectorization.ArrayRefStruct{:s, Symbol(\"##vptr##_s\")}(0x00000000000000000000000000000101, 0x00000000000000000000000000000302, 0x00000000000000000000000000000000, 0x00000000000000000000000000000101), LoopVectorization.ArrayRefStruct{:V, Symbol(\"##vptr##_V\")}(0x00000000000000000000000000000101, 0x00000000000000000000000000000201, 0x00000000000000000000000000000000, 0x00000000000000000000000000000101), LoopVectorization.ArrayRefStruct{:out, Symbol(\"##vptr##_out\")}(0x00000000000000000000000000000201, 0x00000000000000000000000000000c01, 0x00000000000000000000000000000000, 0x00000000000000000000000000000101))}, ::Val{(0, (), (), ((2, (2, 64, true)), (4, (1, 64, true)), (8, (3, 64, true)), (11, (4, 64, true))), (), ((18, LoopVectorization.IntOrFloat),), ())}, ::Val{(:c, :j, :l, :p)}, ::Val{Tuple{Tuple{StrideArraysCore.CloseOpen{Static.StaticInt{0}, Int64}, StrideArraysCore.CloseOpen{Static.StaticInt{0}, Int64}, ArrayInterface.OptionallyStaticUnitRange{Static.StaticInt{1}, Int64}, ArrayInterface.OptionallyStaticUnitRange{Static.StaticInt{1}, Static.StaticInt{4}}}, Tuple{VectorizationBase.GroupedStridedPointers{Tuple{Ptr{UInt8}, Ptr{Float64}, Ptr{Float64}}, (1, 1, 1), (0, 0, 0), ((1, 2), (1, 2), (1, 2)), ((1, 2), (3, 4), (5, 6)), Tuple{Static.StaticInt{1}, Int64, Static.StaticInt{8}, Int64, Static.StaticInt{8}, Int64}, Tuple{Static.StaticInt{1}, Static.StaticInt{0}, Static.StaticInt{0}, Static.StaticInt{0}, Static.StaticInt{0}, Static.StaticInt{0}}}}}}, ::Int64, ::Int64, ::Int64, ::Ptr{UInt8}, ::Ptr{Float64}, ::Ptr{Float64}, ::Int64, ::Int64, ::Int64)",
      "   @ LoopVectorization ~/.julia/packages/LoopVectorization/OVqp6/src/reconstruct_loopset.jl:706",
      " [4] my_gemm_unroll(out::Matrix{Float64}, s::Matrix{UInt8}, V::Matrix{Float64})",
      "   @ Main ./In[11]:45",
      " [5] top-level scope",
      "   @ In[12]:1",
      " [6] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "my_gemm_unroll(out_test3, s, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
