{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling SnpArrays [4e780e97-f5bf-4111-9dc4-b70aaf691b06]\n",
      "└ @ Base loading.jl:1317\n",
      "WARNING: could not import DataFrames.DataFrame! into SnpArrays\n",
      "┌ Info: Precompiling MendelIHT [921c7187-1484-5754-b919-5d3ed9ac03c4]\n",
      "└ @ Base loading.jl:1317\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness: No center/scale/impute\n",
    "We want to do $C = AB$ where\n",
    "+ $C = m \\times n$\n",
    "+ $A = m \\times n$\n",
    "+ $B = n \\times p$\n",
    "+ SnpArray model = Additive, dominant, recessive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching vashr(::VectorizationBase.VecUnroll{1, 4, UInt8, VectorizationBase.Vec{4, UInt8}}, ::VectorizationBase.Vec{4, UInt8})\n\u001b[0mClosest candidates are:\n\u001b[0m  vashr(::Any, \u001b[91m::Static.StaticInt{M}\u001b[39m) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:38\n\u001b[0m  vashr(\u001b[91m::Static.StaticInt{M}\u001b[39m, ::Any) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:36\n\u001b[0m  vashr(\u001b[91m::VectorizationBase.MM{W, X, T1}\u001b[39m, ::VectorizationBase.AbstractSIMDVector{W, T2}) where {W, X, T1<:Union{Int16, Int32, Int64, Int8}, T2<:Union{UInt16, UInt32, UInt64, UInt8}} at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/ranges.jl:205\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching vashr(::VectorizationBase.VecUnroll{1, 4, UInt8, VectorizationBase.Vec{4, UInt8}}, ::VectorizationBase.Vec{4, UInt8})\n\u001b[0mClosest candidates are:\n\u001b[0m  vashr(::Any, \u001b[91m::Static.StaticInt{M}\u001b[39m) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:38\n\u001b[0m  vashr(\u001b[91m::Static.StaticInt{M}\u001b[39m, ::Any) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:36\n\u001b[0m  vashr(\u001b[91m::VectorizationBase.MM{W, X, T1}\u001b[39m, ::VectorizationBase.AbstractSIMDVector{W, T2}) where {W, X, T1<:Union{Int16, Int32, Int64, Int8}, T2<:Union{UInt16, UInt32, UInt64, UInt8}} at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/ranges.jl:205\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] >>",
      "   @ ~/.julia/packages/VectorizationBase/bYx3Z/src/base_defs.jl:176 [inlined]",
      " [2] macro expansion",
      "   @ ~/.julia/packages/LoopVectorization/O8WW6/src/reconstruct_loopset.jl:630 [inlined]",
      " [3] _avx_!(#unused#::Val{(false, 0, 0, false, 4, 32, 15, 64, 32768, 262144, 16777216, 0x0000000000000001)}, #unused#::Val{(:LoopVectorization, :getindex, LoopVectorization.OperationStruct(0x0000000000000032, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.memload, 0x01, 0x01), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x02), :p, :p, LoopVectorization.OperationStruct(0x0000000000000004, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.loopvalue, 0x00, 0x03), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x04), :LoopVectorization, :-, LoopVectorization.OperationStruct(0x0000000000000004, 0x0000000000000000, 0x0000000000000000, 0x0000000000000304, LoopVectorization.compute, 0x00, 0x05), :LoopVectorization, :mul_fast, LoopVectorization.OperationStruct(0x0000000000000004, 0x0000000000000000, 0x0000000000000000, 0x0000000000000205, LoopVectorization.compute, 0x00, 0x06), :LoopVectorization, :>>, LoopVectorization.OperationStruct(0x0000000000000324, 0x0000000000000000, 0x0000000000000000, 0x0000000000000106, LoopVectorization.compute, 0x00, 0x07), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x08), :LoopVectorization, :&, LoopVectorization.OperationStruct(0x0000000000000324, 0x0000000000000000, 0x0000000000000000, 0x0000000000000708, LoopVectorization.compute, 0x00, 0x09), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x0a), :LoopVectorization, :+, LoopVectorization.OperationStruct(0x0000000000000004, 0x0000000000000000, 0x0000000000000000, 0x0000000000000a03, LoopVectorization.compute, 0x00, 0x0b), :l, :l, LoopVectorization.OperationStruct(0x0000000000000003, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.loopvalue, 0x00, 0x0c), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x0d), :LoopVectorization, :muladd, LoopVectorization.OperationStruct(0x0000000000000034, 0x0000000000000000, 0x0000000000000000, 0x00000000000a0c0b, LoopVectorization.compute, 0x00, 0x0e), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x0f), :LoopVectorization, :>=, LoopVectorization.OperationStruct(0x0000000000000324, 0x0000000000000000, 0x0000000000000000, 0x0000000000000902, LoopVectorization.compute, 0x00, 0x10), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x11), :LoopVectorization, :(==), LoopVectorization.OperationStruct(0x0000000000000324, 0x0000000000000000, 0x0000000000000000, 0x0000000000000908, LoopVectorization.compute, 0x00, 0x12), :LoopVectorization, :+, LoopVectorization.OperationStruct(0x0000000000000324, 0x0000000000000000, 0x0000000000000000, 0x0000000000001012, LoopVectorization.compute, 0x00, 0x13), :LoopVectorization, :getindex, LoopVectorization.OperationStruct(0x0000000000000021, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.memload, 0x02, 0x14), :LoopVectorization, :getindex, LoopVectorization.OperationStruct(0x0000000000000002, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.memload, 0x03, 0x15), :LoopVectorization, :mul_fast, LoopVectorization.OperationStruct(0x0000000000000021, 0x0000000000000000, 0x0000000000000000, 0x0000000000001415, LoopVectorization.compute, 0x00, 0x16), :LoopVectorization, :LOOPCONSTANTINSTRUCTION, LoopVectorization.OperationStruct(0x0000000000000000, 0x0000000000000000, 0x0000000000000000, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x17), :LoopVectorization, :getindex, LoopVectorization.OperationStruct(0x0000000000000341, 0x0000000000000000, 0x0000000000000000, 0x000000000000000e, LoopVectorization.memload, 0x04, 0x18), :numericconstant, Symbol(\"###reduction##zero###30###\"), LoopVectorization.OperationStruct(0x0000000000000341, 0x0000000000000000, 0x0000000000000002, 0x0000000000000000, LoopVectorization.constant, 0x00, 0x19), :LoopVectorization, :vfmadd_fast, LoopVectorization.OperationStruct(0x0000000000003241, 0x0000000000000002, 0x0000000000000000, 0x0000000000131619, LoopVectorization.compute, 0x00, 0x19), :LoopVectorization, :reduced_add, LoopVectorization.OperationStruct(0x0000000000000341, 0x0000000000000002, 0x0000000000000000, 0x0000000000001a18, LoopVectorization.compute, 0x00, 0x18), :LoopVectorization, :setindex!, LoopVectorization.OperationStruct(0x0000000000000341, 0x0000000000000000, 0x0000000000000000, 0x0000000000001b0e, LoopVectorization.memstore, 0x04, 0x1a))}, #unused#::Val{(LoopVectorization.ArrayRefStruct{:s, Symbol(\"##vptr##_s\")}(0x0000000000000101, 0x0000000000000302, 0x0000000000000000, 0x0000000000000101), LoopVectorization.ArrayRefStruct{:V, Symbol(\"##vptr##_V\")}(0x0000000000000101, 0x0000000000000201, 0x0000000000000000, 0x0000000000000101), LoopVectorization.ArrayRefStruct{:σinv, Symbol(\"##vptr##_σinv\")}(0x0000000000000001, 0x0000000000000002, 0x0000000000000000, 0x0000000000000001), LoopVectorization.ArrayRefStruct{:out, Symbol(\"##vptr##_out\")}(0x0000000000000201, 0x0000000000000e01, 0x000000000000fc00, 0x0000000000000101))}, #unused#::Val{(0, (), (), ((2, (2, 64, true)), (4, (1, 64, true)), (8, (3, 64, true)), (10, (4, 64, true))), (), ((25, LoopVectorization.IntOrFloat),), ())}, #unused#::Val{(:c, :j, :l, :p)}, tuple#args#::Tuple{Tuple{ArrayInterface.OptionallyStaticUnitRange{Static.StaticInt{1}, Int64}, ArrayInterface.OptionallyStaticUnitRange{Static.StaticInt{1}, Int64}, ArrayInterface.OptionallyStaticUnitRange{Static.StaticInt{1}, Int64}, ArrayInterface.OptionallyStaticUnitRange{Static.StaticInt{1}, Static.StaticInt{4}}}, Tuple{VectorizationBase.GroupedStridedPointers{Tuple{Ptr{UInt8}, Ptr{Float64}, Ptr{Float64}, Ptr{Float64}}, (1, 1, 1, 1), (0, 0, 0, 0), ((1, 2), (1, 2), (1,), (1, 2)), ((1, 2), (3, 4), (5,), (6, 7)), Tuple{Static.StaticInt{1}, Int64, Static.StaticInt{8}, Int64, Static.StaticInt{8}, Static.StaticInt{8}, Int64}, NTuple{7, Static.StaticInt{1}}}}})",
      "   @ LoopVectorization ~/.julia/packages/LoopVectorization/O8WW6/src/reconstruct_loopset.jl:630",
      " [4] _snparray_AX_additive!(out::SubArray{Float64, 2, Matrix{Float64}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}, s::SubArray{UInt8, 2, Matrix{UInt8}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}, V::SubArray{Float64, 2, Matrix{Float64}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}, srows::Int64, scols::Int64, Vcols::Int64, μ::SubArray{Float64, 1, Vector{Float64}, Tuple{UnitRange{Int64}}, true}, σinv::SubArray{Float64, 1, Vector{Float64}, Tuple{UnitRange{Int64}}, true})",
      "   @ SnpArrays ~/.julia/dev/SnpArrays/src/linalg_direct.jl:594",
      " [5] _snparray_AX_tile!(C::Matrix{Float64}, A::Matrix{UInt8}, B::Matrix{Float64}, model::Val{1}, μ::Vector{Float64}, impute::Bool, rows_filled::Int64, σinv::Vector{Float64})",
      "   @ SnpArrays ~/.julia/dev/SnpArrays/src/linalg_direct.jl:285",
      " [6] mul!(out::Matrix{Float64}, sla::SnpLinAlg{Float64}, V::Matrix{Float64})",
      "   @ SnpArrays ~/.julia/dev/SnpArrays/src/linalg_direct.jl:126",
      " [7] top-level scope",
      "   @ In[28]:13",
      " [8] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [9] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "model = ADDITIVE_MODEL\n",
    "center = false\n",
    "scale = false\n",
    "impute = false\n",
    "m = 4097\n",
    "n = 1025\n",
    "p = 1025\n",
    "x = simulate_random_snparray(undef, m, n)\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=model, impute=impute, center=center, scale=scale)\n",
    "B = ones(n, p)\n",
    "C = zeros(m, p)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "\n",
    "Ctrue = convert(Matrix{Float64}, x, impute=impute, model=model, center=center, scale=scale) * B\n",
    "@show all(C .≈ Ctrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4097×1025 Matrix{Float64}:\n",
       " 2096.0  2096.0  2096.0  2096.0  2096.0  …  2096.0  2096.0  2096.0  2096.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       " 2110.0  2110.0  2110.0  2110.0  2110.0     2110.0  2110.0  2110.0  2110.0\n",
       "    0.0     0.0     0.0     0.0     0.0  …     0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       " 2036.0  2036.0  2036.0  2036.0  2036.0     2036.0  2036.0  2036.0  2036.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0  …     0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       " 2082.0  2082.0  2082.0  2082.0  2082.0     2082.0  2082.0  2082.0  2082.0\n",
       "    ⋮                                    ⋱                          \n",
       "    0.0     0.0     0.0     0.0     0.0  …     0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       " 2065.0  2065.0  2065.0  2065.0  2065.0     2065.0  2065.0  2065.0  2065.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0  …     0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       " 2112.0  2112.0  2112.0  2112.0  2112.0     2112.0  2112.0  2112.0  2112.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "    0.0     0.0     0.0     0.0     0.0  …     0.0     0.0     0.0     0.0\n",
       "  535.0   535.0   535.0   535.0   535.0      535.0   535.0   535.0   535.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4097×1025 Matrix{Float64}:\n",
       " 524.0  524.0  524.0  524.0  524.0  …  524.0  524.0  524.0  524.0  524.0\n",
       " 524.0  524.0  524.0  524.0  524.0     524.0  524.0  524.0  524.0  524.0\n",
       " 525.0  525.0  525.0  525.0  525.0     525.0  525.0  525.0  525.0  525.0\n",
       " 523.0  523.0  523.0  523.0  523.0     523.0  523.0  523.0  523.0  523.0\n",
       " 553.0  553.0  553.0  553.0  553.0     553.0  553.0  553.0  553.0  553.0\n",
       " 524.0  524.0  524.0  524.0  524.0  …  524.0  524.0  524.0  524.0  524.0\n",
       " 502.0  502.0  502.0  502.0  502.0     502.0  502.0  502.0  502.0  502.0\n",
       " 531.0  531.0  531.0  531.0  531.0     531.0  531.0  531.0  531.0  531.0\n",
       " 516.0  516.0  516.0  516.0  516.0     516.0  516.0  516.0  516.0  516.0\n",
       " 505.0  505.0  505.0  505.0  505.0     505.0  505.0  505.0  505.0  505.0\n",
       " 499.0  499.0  499.0  499.0  499.0  …  499.0  499.0  499.0  499.0  499.0\n",
       " 516.0  516.0  516.0  516.0  516.0     516.0  516.0  516.0  516.0  516.0\n",
       " 512.0  512.0  512.0  512.0  512.0     512.0  512.0  512.0  512.0  512.0\n",
       "   ⋮                                ⋱    ⋮                         \n",
       " 529.0  529.0  529.0  529.0  529.0  …  529.0  529.0  529.0  529.0  529.0\n",
       " 527.0  527.0  527.0  527.0  527.0     527.0  527.0  527.0  527.0  527.0\n",
       " 509.0  509.0  509.0  509.0  509.0     509.0  509.0  509.0  509.0  509.0\n",
       " 490.0  490.0  490.0  490.0  490.0     490.0  490.0  490.0  490.0  490.0\n",
       " 527.0  527.0  527.0  527.0  527.0     527.0  527.0  527.0  527.0  527.0\n",
       " 544.0  544.0  544.0  544.0  544.0  …  544.0  544.0  544.0  544.0  544.0\n",
       " 504.0  504.0  504.0  504.0  504.0     504.0  504.0  504.0  504.0  504.0\n",
       " 528.0  528.0  528.0  528.0  528.0     528.0  528.0  528.0  528.0  528.0\n",
       " 531.0  531.0  531.0  531.0  531.0     531.0  531.0  531.0  531.0  531.0\n",
       " 534.0  534.0  534.0  534.0  534.0     534.0  534.0  534.0  534.0  534.0\n",
       " 519.0  519.0  519.0  519.0  519.0  …  519.0  519.0  519.0  519.0  519.0\n",
       " 535.0  535.0  535.0  535.0  535.0     535.0  535.0  535.0  535.0  535.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ctrue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness: center/scale/impute\n",
    "\n",
    "If we want to center/scale the SnpArray, we have\n",
    "$$\n",
    "C_{ij} = \\sum_{k} \\left(\\frac{A_{ik} - \\mu_k}{\\sigma_k^2}\\right)B_{kj} = \\sum_{k} \\frac{A_{ik}B_{kj} - \\mu_kB_{kj}}{\\sigma_k^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all(C .≈ Ctrue) = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ADDITIVE_MODEL\n",
    "center = true\n",
    "scale = true\n",
    "impute = false\n",
    "m = 4097\n",
    "n = 1025\n",
    "p = 1025\n",
    "x = simulate_random_snparray(undef, m, n)\n",
    "if impute\n",
    "    for j in 1:n, i in 1:m\n",
    "        rand() < 0.01 && (x[i, j] = 0x01) # create ~1% missings\n",
    "    end\n",
    "end\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=model, impute=impute, center=center, scale=scale)\n",
    "B = ones(n, p)\n",
    "C = zeros(m, p)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "\n",
    "Ctrue = convert(Matrix{Float64}, x, impute=impute, model=model, center=center, scale=scale) * B\n",
    "@show all(C .≈ Ctrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed: SnpLinAlg-(matrix) vs multiple SnpLinAlg-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adhoc_mul! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C = AB by multiple C[:, i] = AB[:, i]\n",
    "function adhoc_mul!(\n",
    "    out::AbstractMatrix, \n",
    "    st::AbstractSnpLinAlg,\n",
    "    v::AbstractMatrix)\n",
    "    for i in 1:size(v, 2)\n",
    "        outi = @view(out[:, i])\n",
    "        vi = @view(v[:, i])\n",
    "        SnpArrays.mul!(outi, st, vi)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 1273, Miter = 1, Mrem = 228\n",
      "N = 10000, Niter = 9, Nrem = 784\n",
      "P = 2, Piter = 0, Prem = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5092   # number of samples\n",
    "p = 10000  # number of SNPs\n",
    "r = 2      # number of traits\n",
    "x = simulate_random_snparray(undef, n, p)\n",
    "\n",
    "# test correctness\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "B = ones(p, r)\n",
    "C = zeros(n, r)\n",
    "Ctest = zeros(n, r)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "adhoc_mul!(Ctest, A, B)\n",
    "all(Ctest .≈ C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     56.664 ms (0.00% GC)\n",
       "  median time:      59.099 ms (0.00% GC)\n",
       "  mean time:        59.197 ms (0.00% GC)\n",
       "  maximum time:     69.516 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          85\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearAlgebra.mul!($C, $A, $B) # SnpLinAlg-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  288 bytes\n",
       "  allocs estimate:  4\n",
       "  --------------\n",
       "  minimum time:     60.921 ms (0.00% GC)\n",
       "  median time:      62.778 ms (0.00% GC)\n",
       "  mean time:        62.858 ms (0.00% GC)\n",
       "  maximum time:     75.957 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          80\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark adhoc_mul!($Ctest, $A, $B) # multiple SnpLinAlg-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     17.510 ms (0.00% GC)\n",
       "  median time:      17.860 ms (0.00% GC)\n",
       "  mean time:        18.052 ms (0.00% GC)\n",
       "  maximum time:     21.712 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          277\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Afloat = convert(Matrix{Float64}, A)\n",
    "BLAS.set_num_threads(8)\n",
    "@benchmark LinearAlgebra.mul!($C, $Afloat, $B) # BLAS with 8 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     48.364 ms (0.00% GC)\n",
       "  median time:      50.801 ms (0.00% GC)\n",
       "  mean time:        51.121 ms (0.00% GC)\n",
       "  maximum time:     56.792 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          98\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.set_num_threads(1)\n",
    "@benchmark LinearAlgebra.mul!($C, $Afloat, $B) # BLAS with 1 threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5092\n",
    "p = 10000\n",
    "q = 5\n",
    "x = simulate_random_snparray(undef, n, p)\n",
    "\n",
    "# test correctness\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "B = ones(p, q)\n",
    "C = zeros(n, q)\n",
    "Ctest = zeros(n, q)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "adhoc_mul!(Ctest, A, B)\n",
    "all(Ctest .≈ C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     63.364 ms (0.00% GC)\n",
       "  median time:      66.311 ms (0.00% GC)\n",
       "  mean time:        66.760 ms (0.00% GC)\n",
       "  maximum time:     82.072 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          75\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearAlgebra.mul!($C, $A, $B) # SnpLinAlg-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  720 bytes\n",
       "  allocs estimate:  10\n",
       "  --------------\n",
       "  minimum time:     151.571 ms (0.00% GC)\n",
       "  median time:      153.847 ms (0.00% GC)\n",
       "  mean time:        154.455 ms (0.00% GC)\n",
       "  maximum time:     165.740 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          33\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark adhoc_mul!($Ctest, $A, $B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     17.992 ms (0.00% GC)\n",
       "  median time:      18.381 ms (0.00% GC)\n",
       "  mean time:        18.582 ms (0.00% GC)\n",
       "  maximum time:     21.774 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          269\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Afloat = convert(Matrix{Float64}, A)\n",
    "BLAS.set_num_threads(8)\n",
    "@benchmark LinearAlgebra.mul!($C, $Afloat, $B) # BLAS with 8 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     54.639 ms (0.00% GC)\n",
       "  median time:      58.390 ms (0.00% GC)\n",
       "  mean time:        57.967 ms (0.00% GC)\n",
       "  maximum time:     63.756 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          87\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.set_num_threads(1)\n",
    "@benchmark LinearAlgebra.mul!($C, $Afloat, $B) # BLAS with 1 threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gesp vs @view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5092\n",
    "p = 1000\n",
    "q = 1000\n",
    "x = simulate_random_snparray(undef, n, p)\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "B = ones(p, q)\n",
    "C = zeros(n, q);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     1.104 s (0.00% GC)\n",
       "  median time:      1.113 s (0.00% GC)\n",
       "  mean time:        1.113 s (0.00% GC)\n",
       "  maximum time:     1.118 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearAlgebra.mul!($C, $A, $B) # gesp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     1.112 s (0.00% GC)\n",
       "  median time:      1.120 s (0.00% GC)\n",
       "  mean time:        1.120 s (0.00% GC)\n",
       "  maximum time:     1.126 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark LinearAlgebra.mul!($C, $A, $B) # @view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Ax$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 1023, Miter = 0, Mrem = 253, rows_filled = 4093 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT\n",
    "using Test\n",
    "\n",
    "# any n between 4097 and 4099 doesn't work!\n",
    "n = 4093\n",
    "p = 10000\n",
    "x = simulate_random_snparray(undef, n, p, min_ma=0)\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "b = ones(p)\n",
    "c = A * b\n",
    "ctrue = convert(Matrix{Float64}, A) * b\n",
    "@test all(c .≈ ctrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $A^tx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT\n",
    "using Test\n",
    "\n",
    "# any n between 8193 and 8195 doesn't work!\n",
    "n = 8193\n",
    "p = 1000\n",
    "x = simulate_random_snparray(undef, n, p, min_ma=0)\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "b = ones(n)\n",
    "c = A' * b\n",
    "ctrue = convert(Matrix{Float64}, A)' * b\n",
    "@test all(c .≈ ctrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## $Ax$ with mean impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT\n",
    "using Test\n",
    "\n",
    "n = 4097\n",
    "p = 10000\n",
    "x = simulate_random_snparray(undef, n, p, min_ma=0) # no missing data\n",
    "x[1, 1025] = 0x01 # missing\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=true, center=false, scale=false)\n",
    "Atrue = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, impute=true, center=false, scale=false)\n",
    "b = ones(p)\n",
    "c = A * b\n",
    "ctrue = Atrue * b\n",
    "@test all(c .≈ ctrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "this_gemm_works (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "\n",
    "function this_gemm_fails(out, s::Matrix{UInt8}, V)\n",
    "    Vcols = size(V, 2)\n",
    "    srows = size(s, 1)\n",
    "    scols = size(s, 2)\n",
    "    k = srows >> 2\n",
    "    rem = srows & 3\n",
    "    @avx for c in 1:Vcols\n",
    "        for j in 1:scols\n",
    "            for l in 1:k\n",
    "                block = s[l, j]\n",
    "                # unrolled loop\n",
    "                p = 1\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 2\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 3\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 4\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    # TODO handle rem\n",
    "end\n",
    "\n",
    "function this_gemm_works(out, s::Matrix{UInt8}, V)\n",
    "    Vcols = size(V, 2)\n",
    "    srows = size(s, 1)\n",
    "    scols = size(s, 2)\n",
    "    k = srows >> 2\n",
    "    rem = srows & 3\n",
    "    for c in 1:Vcols\n",
    "        @avx for j in 1:scols\n",
    "            for l in 1:k\n",
    "                block = s[l, j]\n",
    "                # unrolled loop\n",
    "                p = 1\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 2\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 3\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "                p = 4\n",
    "                Aij = (block >> (2 * (p - 1))) & 3\n",
    "                out[4*(l - 1) + p, c] += ((Aij >= 2) + (Aij == 3)) * V[j, c]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    # TODO handle rem\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching vashr(::VectorizationBase.Vec{4, Float64}, ::VectorizationBase.Vec{4, Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  vashr(::Any, \u001b[91m::Static.StaticInt{M}\u001b[39m) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:38\n\u001b[0m  vashr(\u001b[91m::Static.StaticInt{M}\u001b[39m, ::Any) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:36",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching vashr(::VectorizationBase.Vec{4, Float64}, ::VectorizationBase.Vec{4, Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  vashr(::Any, \u001b[91m::Static.StaticInt{M}\u001b[39m) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:38\n\u001b[0m  vashr(\u001b[91m::Static.StaticInt{M}\u001b[39m, ::Any) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:36",
      "",
      "Stacktrace:",
      " [1] fmap",
      "   @ ~/.julia/packages/VectorizationBase/bYx3Z/src/vecunroll/fmap.jl:10 [inlined]",
      " [2] vashr",
      "   @ ~/.julia/packages/VectorizationBase/bYx3Z/src/vecunroll/fmap.jl:94 [inlined]",
      " [3] >>",
      "   @ ~/.julia/packages/VectorizationBase/bYx3Z/src/base_defs.jl:86 [inlined]",
      " [4] macro expansion",
      "   @ ~/.julia/packages/LoopVectorization/O8WW6/src/reconstruct_loopset.jl:630 [inlined]",
      " [5] _avx_!",
      "   @ ~/.julia/packages/LoopVectorization/O8WW6/src/reconstruct_loopset.jl:630 [inlined]",
      " [6] this_gemm_works(out::Matrix{Float64}, s::Matrix{UInt8}, V::Matrix{Float64})",
      "   @ Main ./In[7]:41",
      " [7] top-level scope",
      "   @ In[8]:4",
      " [8] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [9] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "out = zeros(100, 10)\n",
    "s = rand(UInt8, 100, 100)\n",
    "V = rand(100, 10)\n",
    "this_gemm_works(out, s, V) # runs without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching vashr(::VectorizationBase.Vec{4, Float64}, ::VectorizationBase.Vec{4, Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  vashr(::Any, \u001b[91m::Static.StaticInt{M}\u001b[39m) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:38\n\u001b[0m  vashr(\u001b[91m::Static.StaticInt{M}\u001b[39m, ::Any) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:36",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching vashr(::VectorizationBase.Vec{4, Float64}, ::VectorizationBase.Vec{4, Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  vashr(::Any, \u001b[91m::Static.StaticInt{M}\u001b[39m) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:38\n\u001b[0m  vashr(\u001b[91m::Static.StaticInt{M}\u001b[39m, ::Any) where M at /Users/biona001/.julia/packages/VectorizationBase/bYx3Z/src/static.jl:36",
      "",
      "Stacktrace:",
      " [1] >>",
      "   @ ~/.julia/packages/LoopVectorization/O8WW6/src/reconstruct_loopset.jl:0 [inlined]",
      " [2] macro expansion",
      "   @ ~/.julia/packages/LoopVectorization/O8WW6/src/reconstruct_loopset.jl:630 [inlined]",
      " [3] _avx_!",
      "   @ ~/.julia/packages/LoopVectorization/O8WW6/src/reconstruct_loopset.jl:630 [inlined]",
      " [4] this_gemm_fails(out::Matrix{Float64}, s::Matrix{UInt8}, V::Matrix{Float64})",
      "   @ Main ./In[7]:11",
      " [5] top-level scope",
      "   @ In[9]:1",
      " [6] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "this_gemm_fails(out, s, V) # throws vashr error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
