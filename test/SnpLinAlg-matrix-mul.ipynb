{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling SnpArrays [4e780e97-f5bf-4111-9dc4-b70aaf691b06]\n",
      "└ @ Base loading.jl:1317\n",
      "WARNING: could not import DataFrames.DataFrame! into SnpArrays\n",
      "┌ Info: Precompiling MendelIHT [921c7187-1484-5754-b919-5d3ed9ac03c4]\n",
      "└ @ Base loading.jl:1317\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using SnpArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using LoopVectorization\n",
    "using MendelIHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No center/scale/impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = srows >> 2 # fast div(srows, 4)\n",
    "rem = srows & 3 # fast rem(srows, 4)\n",
    "packedstride = size(s, 1)\n",
    "\n",
    "# out[i, k] = s[i, j] * V[j, k] for j in 1:n\n",
    "@avx for k in 1:size(s, 2)\n",
    "    for j in 1:size(V, 2)\n",
    "        for i in 1:size(s, 1)\n",
    "            l = 2 * ((i-1) & 3)\n",
    "            block = s[(j-1) * packedstride + ((i-1) >> 2) + 1]\n",
    "            Aij = (block >> l) & 3\n",
    "            out[i, k] += $expr\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 125, Miter = 0, Mrem = 125\n",
      "N = 1024, Niter = 1, Nrem = 0\n",
      "P = 1024, Piter = 1, Prem = 0\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: _ftn! not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: _ftn! not defined",
      "",
      "Stacktrace:",
      " [1] _snparray_AX_additive!(out::SubArray{Float64, 2, Matrix{Float64}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}, s::SubArray{UInt8, 2, Matrix{UInt8}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}, V::SubArray{Float64, 2, Matrix{Float64}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}, srows::Int64, scols::Int64, Vcols::Int64, μ::Vector{Float64})",
      "   @ SnpArrays ~/.julia/dev/SnpArrays/src/linalg_direct.jl:575",
      " [2] _snparray_AX_tile!(C::Matrix{Float64}, A::Matrix{UInt8}, B::Matrix{Float64}, model::Val{1}, μ::Vector{Float64}, impute::Bool)",
      "   @ SnpArrays ~/.julia/dev/SnpArrays/src/linalg_direct.jl:327",
      " [3] mul!(out::Matrix{Float64}, sla::SnpLinAlg{Float64}, V::Matrix{Float64})",
      "   @ SnpArrays ~/.julia/dev/SnpArrays/src/linalg_direct.jl:161",
      " [4] top-level scope",
      "   @ In[22]:10",
      " [5] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [6] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "# x = SnpArray(SnpArrays.datadir(\"EUR_subset.bed\"))\n",
    "n = 500\n",
    "p = 1024\n",
    "q = 1024\n",
    "x = simulate_random_snparray(undef, n, p)\n",
    "\n",
    "A = SnpLinAlg{Float64}(x, model=ADDITIVE_MODEL, impute=false, center=false, scale=false)\n",
    "B = ones(p, q)\n",
    "C = zeros(n, q)\n",
    "LinearAlgebra.mul!(C, A, B)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500×1024 Matrix{Float64}:\n",
       " 516.0  516.0  516.0  516.0  516.0  …  516.0  516.0  516.0  516.0  516.0\n",
       " 517.0  517.0  517.0  517.0  517.0     517.0  517.0  517.0  517.0  517.0\n",
       " 479.0  479.0  479.0  479.0  479.0     479.0  479.0  479.0  479.0  479.0\n",
       " 516.0  516.0  516.0  516.0  516.0     516.0  516.0  516.0  516.0  516.0\n",
       " 499.0  499.0  499.0  499.0  499.0     499.0  499.0  499.0  499.0  499.0\n",
       " 474.0  474.0  474.0  474.0  474.0  …  474.0  474.0  474.0  474.0  474.0\n",
       " 511.0  511.0  511.0  511.0  511.0     511.0  511.0  511.0  511.0  511.0\n",
       " 493.0  493.0  493.0  493.0  493.0     493.0  493.0  493.0  493.0  493.0\n",
       " 504.0  504.0  504.0  504.0  504.0     504.0  504.0  504.0  504.0  504.0\n",
       " 488.0  488.0  488.0  488.0  488.0     488.0  488.0  488.0  488.0  488.0\n",
       " 498.0  498.0  498.0  498.0  498.0  …  498.0  498.0  498.0  498.0  498.0\n",
       " 523.0  523.0  523.0  523.0  523.0     523.0  523.0  523.0  523.0  523.0\n",
       " 516.0  516.0  516.0  516.0  516.0     516.0  516.0  516.0  516.0  516.0\n",
       "   ⋮                                ⋱           ⋮                  \n",
       " 523.0  523.0  523.0  523.0  523.0     523.0  523.0  523.0  523.0  523.0\n",
       " 490.0  490.0  490.0  490.0  490.0     490.0  490.0  490.0  490.0  490.0\n",
       " 517.0  517.0  517.0  517.0  517.0  …  517.0  517.0  517.0  517.0  517.0\n",
       " 553.0  553.0  553.0  553.0  553.0     553.0  553.0  553.0  553.0  553.0\n",
       " 520.0  520.0  520.0  520.0  520.0     520.0  520.0  520.0  520.0  520.0\n",
       " 492.0  492.0  492.0  492.0  492.0     492.0  492.0  492.0  492.0  492.0\n",
       " 537.0  537.0  537.0  537.0  537.0     537.0  537.0  537.0  537.0  537.0\n",
       " 506.0  506.0  506.0  506.0  506.0  …  506.0  506.0  506.0  506.0  506.0\n",
       " 491.0  491.0  491.0  491.0  491.0     491.0  491.0  491.0  491.0  491.0\n",
       " 518.0  518.0  518.0  518.0  518.0     518.0  518.0  518.0  518.0  518.0\n",
       " 480.0  480.0  480.0  480.0  480.0     480.0  480.0  480.0  480.0  480.0\n",
       " 477.0  477.0  477.0  477.0  477.0     477.0  477.0  477.0  477.0  477.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ctrue = convert(Matrix{Float64}, A) * B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple gemm kernel\n",
    "\n",
    "see https://github.com/JuliaSIMD/LoopVectorization.jl/issues/136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256×1024 Matrix{Float64}:\n",
       " 66434.3  64444.8  64477.0  64325.0  …  64434.7  64684.9  65697.5  67257.2\n",
       " 64257.3  61606.1  63287.7  63319.2     63468.6  62763.4  62964.8  63074.6\n",
       " 67281.3  66249.3  64499.8  66071.7     66680.0  64896.3  67123.5  67308.1\n",
       " 63134.7  63196.3  62403.8  62460.3     64281.3  62370.7  63617.7  63397.0\n",
       " 66956.1  66625.4  65609.6  64534.9     64802.6  65023.1  66008.6  66759.5\n",
       " 67794.7  64426.7  64144.5  64350.9  …  64788.2  63908.4  64972.4  64790.6\n",
       " 67356.6  64806.9  64644.5  66182.2     65452.9  64286.9  66074.6  66276.3\n",
       " 66572.2  64912.0  65080.6  64689.8     65311.9  64538.2  65481.4  66282.2\n",
       " 65137.1  63702.4  64275.9  64050.9     65489.8  63791.7  64423.3  65201.1\n",
       " 64235.2  63802.3  63511.9  62459.4     63186.4  62899.6  62262.1  64026.0\n",
       " 66430.6  66459.6  65568.3  65449.1  …  66250.1  64175.8  66636.0  66110.1\n",
       " 68341.8  66758.4  66542.2  65753.8     66790.0  67162.7  67627.1  67548.5\n",
       " 64793.8  64138.0  63631.7  64048.2     64150.4  63272.4  65139.7  65746.7\n",
       "     ⋮                               ⋱      ⋮                      \n",
       " 64909.3  63169.2  63825.3  63237.8     65406.2  62548.2  63314.1  63941.3\n",
       " 68006.1  65483.8  65495.8  65198.2  …  66011.6  65386.9  65467.3  65136.2\n",
       " 64919.7  64142.6  64638.7  63181.2     65052.9  62670.3  64779.5  64908.7\n",
       " 67103.2  64528.2  65941.1  66001.8     68008.2  65199.1  67183.2  67231.2\n",
       " 65775.1  66513.2  65017.9  64776.2     65377.0  65310.5  66249.4  66249.1\n",
       " 64590.9  62807.4  64233.3  64242.2     66138.8  65528.6  64355.9  64340.0\n",
       " 66187.5  65439.9  64110.7  63673.8  …  65435.5  63524.4  63216.7  65149.1\n",
       " 63213.1  63198.1  63743.1  62969.8     63869.7  63882.9  64899.1  66796.7\n",
       " 63439.5  64383.9  63795.5  61855.6     63938.5  62268.1  63016.9  64126.4\n",
       " 69280.6  68424.5  67666.8  66812.3     68387.1  67187.5  68156.8  69901.5\n",
       " 65431.3  63721.1  63807.4  62599.1     65645.3  63553.8  64646.6  66822.4\n",
       " 66172.3  65846.5  66902.7  65101.1  …  66185.0  63445.2  65023.4  65601.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs, but not testes for correctness\n",
    "function LinearAlgebra.mul!(C::Matrix{T}, A::Matrix{UInt8}, B::Vector{T}) where T \n",
    "    packedstride = size(A, 1)\n",
    "    m = size(A, 1)\n",
    "    n = size(A, 2)\n",
    "    q = size(B, 2)\n",
    "    # C[i, k] = A[i, j] * B[j, k] for j in 1:n\n",
    "    @avx for k in 1:n\n",
    "        for j in 1:q\n",
    "            for i in 1:m\n",
    "                l = 2 * ((i-1) & 3)\n",
    "                block = A[(j-1) * packedstride + ((i-1) >> 2) + 1]\n",
    "                Aij = (block >> l) & 3\n",
    "                C[i, k] += (((Aij >= 2) + (Aij >= 3))) * B[j, k]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    y\n",
    "end\n",
    "n = 1024\n",
    "C = rand(n>>2, n)\n",
    "B = rand(n, n)\n",
    "A = rand(UInt8, (n>>2) + (n%4 != 0), n)\n",
    "mul!(C, A, B)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
